version: v2
description: training_gpt_neo1.3B_deepmindmath_clean
tasks:
  - name: training_gpt_neo1.3B_with_deepmindmath_clean
    image:
      beaker: yasamanr/icl_small.2
    command: [accelerate-launch, --mixed_precision=bf16, --multi_gpu, training/run_clm_no_trainer.py]
    arguments: [--dataset_name, training/load_pile_splits.py, --dataset_file_name, ./pile/deepmind_math_cleaned.jsonl.gz, --model_name_or_path, EleutherAI/gpt-neo-1.3b, --per_device_train_batch_size, "2", --gradient_accumulation_steps, "20", --with_tracking, --num_train_epochs, "1", --output_dir, /net/nfs.cirrascale/allennlp/yasamanr/icl_small/output_results/, --num_warmup_steps=500, --block_size=2024, --checkpointing_steps, "500"]
    datasets:
      - mountPath: /net/nfs.cirrascale/allennlp/yasamanr/icl_small
        source:
          hostPath: /net/nfs.cirrascale/allennlp/yasamanr/icl_small
    result:
      path: /output
    resources:
      gpuCount: 4
    context:
      priority: normal
    constraints:
      cluster:
        - ai2/allennlp-cirrascale